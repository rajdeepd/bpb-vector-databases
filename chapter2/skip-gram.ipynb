{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb5d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(10)\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "import nltk\n",
    "#Import stopwords\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9250fce",
   "metadata": {},
   "source": [
    "Let us start with a simplified corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f2be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'drink milk',\n",
    "    'drink cold water',\n",
    "    'drink cold cola',\n",
    "    'drink juice',\n",
    "    'drink cola',\n",
    "    'eat bacon',\n",
    "    'eat mango',\n",
    "    'eat cherry',\n",
    "    'eat apple',\n",
    "    'juice with sugar',\n",
    "    'cola with sugar',\n",
    "    'mango is fruit',\n",
    "    'apple is fruit',\n",
    "    'cherry is fruit',\n",
    "    'Berlin is Germany',\n",
    "    'Boston is USA',\n",
    "    'Mercedes from Germany',\n",
    "    'Mercedes is a car',\n",
    "    'Ford from USA',\n",
    "    'Ford is a car'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa80c53",
   "metadata": {},
   "source": [
    "Skip-Gram model tries to predict context given a word. So as input it expect word and as output words which often appears with the inputed one. We have implemented some suportive functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "067628de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary(corpus):\n",
    "    '''Creates a dictionary with all unique words in corpus with id'''\n",
    "    vocabulary = {}\n",
    "    i = 0\n",
    "    for s in corpus:\n",
    "        for w in s.split():\n",
    "            if w not in vocabulary:\n",
    "                vocabulary[w] = i\n",
    "                i+=1\n",
    "    return vocabulary\n",
    "\n",
    "def prepare_set(corpus, n_gram = 1):\n",
    "    '''Creates a dataset with Input column and Outputs columns for neighboring words. \n",
    "       The number of neighbors = n_gram*2'''\n",
    "    columns = ['Input'] + [f'Output{i+1}' for i in range(n_gram*2)]\n",
    "    result = pd.DataFrame(columns = columns)\n",
    "    for sentence in corpus:\n",
    "        for i,w in enumerate(sentence.split()):\n",
    "            inp = [w]\n",
    "            out = []\n",
    "            for n in range(1,n_gram+1):\n",
    "                # look back\n",
    "                if (i-n)>=0:\n",
    "                    out.append(sentence.split()[i-n])\n",
    "                else:\n",
    "                    out.append('<padding>')\n",
    "                \n",
    "                # look forward\n",
    "                if (i+n)<len(sentence.split()):\n",
    "                    out.append(sentence.split()[i+n])\n",
    "                else:\n",
    "                    out.append('<padding>')\n",
    "            row = pd.DataFrame([inp+out], columns = columns)\n",
    "            #result = result.append(row, ignore_index = True)\n",
    "            result = pd.concat([result, row], ignore_index=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6889f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_set_ravel(corpus, n_gram = 1):\n",
    "    '''Creates a dataset with Input column and Output column for neighboring words. \n",
    "       The number of neighbors = n_gram*2'''\n",
    "    columns = ['Input', 'Output']\n",
    "    result = pd.DataFrame(columns = columns)\n",
    "    for sentence in corpus:\n",
    "        for i,w in enumerate(sentence.split()):\n",
    "            inp = w\n",
    "            for n in range(1,n_gram+1):\n",
    "                # look back\n",
    "                if (i-n)>=0:\n",
    "                    out = sentence.split()[i-n]\n",
    "                    row = pd.DataFrame([[inp,out]], columns = columns)\n",
    "                    #result = result.append(row, ignore_index = True)\n",
    "                    result = pd.concat([result, row], ignore_index=True)\n",
    "                \n",
    "                # look forward\n",
    "                if (i+n)<len(sentence.split()):\n",
    "                    out = sentence.split()[i+n]\n",
    "                    row = pd.DataFrame([[inp,out]], columns = columns)\n",
    "                    #result = result.append(row, ignore_index = True)\n",
    "                    result = pd.concat([result, row], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0b4b7",
   "metadata": {},
   "source": [
    "Do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f5f55d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drink milk',\n",
       " 'drink cold water',\n",
       " 'drink cold cola',\n",
       " 'drink juice',\n",
       " 'drink cola',\n",
       " 'eat bacon',\n",
       " 'eat mango',\n",
       " 'eat cherry',\n",
       " 'eat apple',\n",
       " 'juice sugar',\n",
       " 'cola sugar',\n",
       " 'mango fruit',\n",
       " 'apple fruit',\n",
       " 'cherry fruit',\n",
       " 'berlin germany',\n",
       " 'boston usa',\n",
       " 'mercedes germany',\n",
       " 'mercedes car',\n",
       " 'ford usa',\n",
       " 'ford car']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(corpus):\n",
    "    result = []\n",
    "    for i in corpus:\n",
    "        out = nltk.word_tokenize(i)\n",
    "        out = [x.lower() for x in out]\n",
    "        out = [x for x in out if x not in stop_words]\n",
    "        result.append(\" \". join(out))\n",
    "    return result\n",
    "\n",
    "corpus = preprocess(corpus)\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc152a78",
   "metadata": {},
   "source": [
    "Here we are creating a vocabulary which gives id for each word appearing in corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f802ee56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drink': 0,\n",
       " 'milk': 1,\n",
       " 'cold': 2,\n",
       " 'water': 3,\n",
       " 'cola': 4,\n",
       " 'juice': 5,\n",
       " 'eat': 6,\n",
       " 'bacon': 7,\n",
       " 'mango': 8,\n",
       " 'cherry': 9,\n",
       " 'apple': 10,\n",
       " 'sugar': 11,\n",
       " 'fruit': 12,\n",
       " 'berlin': 13,\n",
       " 'germany': 14,\n",
       " 'boston': 15,\n",
       " 'usa': 16,\n",
       " 'mercedes': 17,\n",
       " 'car': 18,\n",
       " 'ford': 19}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = create_vocabulary(corpus)\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737f1bd",
   "metadata": {},
   "source": [
    "Below we can observe the logic. We are taking two neighbors from each side of center word. We can see many padding tokens, that is because maximal length of our sentences is 3, which is why each word will have at least two neighbors being padding. It's done just for presentation purposes. Below you can see some plots, which will help to understand the logic better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691ae782",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"image/skip-gram-image1.png\" width=\"20%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e418b601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output1</th>\n",
       "      <th>Output2</th>\n",
       "      <th>Output3</th>\n",
       "      <th>Output4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drink</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>milk</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milk</td>\n",
       "      <td>drink</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drink</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>cold</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cold</td>\n",
       "      <td>drink</td>\n",
       "      <td>water</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>cold</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "      <td>drink</td>\n",
       "      <td>&lt;padding&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input    Output1    Output2    Output3    Output4\n",
       "0  drink  <padding>       milk  <padding>  <padding>\n",
       "1   milk      drink  <padding>  <padding>  <padding>\n",
       "2  drink  <padding>       cold  <padding>      water\n",
       "3   cold      drink      water  <padding>  <padding>\n",
       "4  water       cold  <padding>      drink  <padding>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb = prepare_set(corpus, n_gram = 2)\n",
    "train_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c9b6e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drink</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milk</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drink</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cold</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input Output\n",
       "0  drink   milk\n",
       "1   milk  drink\n",
       "2  drink   cold\n",
       "3  drink  water\n",
       "4   cold  drink"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb = prepare_set_ravel(corpus, n_gram = 2)\n",
    "train_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8b74c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input  Output\n",
       "0      0       1\n",
       "1      1       0\n",
       "2      0       2\n",
       "3      0       3\n",
       "4      2       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_emb.Input = train_emb.Input.map(vocabulary)\n",
    "train_emb.Output = train_emb.Output.map(vocabulary)\n",
    "train_emb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25ea4e",
   "metadata": {},
   "source": [
    "We have one-hot encoded vector as input and one-hot encoded vector as output. Input and output vectors are equal\n",
    "to length of the vocabolary. All elements are zero except the one which let us identofy which word\n",
    "from the vocabolary is encoded.\n",
    "In between input and output we choose length of a hidden layer. Length of hidden layer defines\n",
    "dimension of the embedding vector. Mulitplying the on hot encoded vector with the weights will activate one row\n",
    "of the weights matrix. One step of the neural network will optimize one row which corresponds\n",
    "to the particular word from the vocabolary. This will allow us to use vectors from weight matrix as \n",
    "representation of words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6babb95",
   "metadata": {},
   "source": [
    "Let is define the loss function. We want to predict the context given a word. So we want to maximise the equation below:\n",
    "\n",
    "$\\max \\prod_{\\text {center }} \\prod_{\\text {context }} P($ context $\\mid$ center $; \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeabe78",
   "metadata": {},
   "source": [
    "It is easier to minimize with neural networks, hence lets convert it into a minimise equation:\n",
    "    \n",
    "$\\min -\\prod_{\\text {center }} \\prod_{\\text {context }} P($ context $\\mid$ center $; \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39232b9d",
   "metadata": {},
   "source": [
    "Adding logrithm before the equation will to use it's useful property, concretely:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb6537",
   "metadata": {},
   "source": [
    "$\\min -\\prod_{\\text {center }} \\prod_{\\text {context }}\\log P($ context $\\mid$ center $; \\theta)$\n",
    "\n",
    "$\\log (a * b)=\\log (a)+\\log (b)$\n",
    "\n",
    "min $-\\sum_{\\text {center }} \\sum_{\\text {context }} \\log P($ context $\\mid$ center $; \\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289bcaf1",
   "metadata": {},
   "source": [
    "Lets define $P($ context $\\mid$ center $; \\theta)$ , softmax function will be used: \n",
    "    $P($ context $\\mid$ center $)=\\frac{\\exp \\left(u_{\\text {context }}^T v_{\\text {center }}\\right)}{\\sum_{\\omega \\in \\text { vocab }} \\exp \\left(u_\\omega^T v_{\\text {center }}\\right)}$\n",
    "    \n",
    "where $u_{\\text {context }}^T v_{\\text {center }}$ is a scalar product of vectors $u$ and $v$ (context, center respectively). Summarizing, the cost or loss function looks like this:\n",
    "\n",
    "$\\min -\\sum_{\\text {center }} \\sum_{\\text {context }} \\log \\frac{\\exp \\left(u_{\\text {context }}^T v_{\\text {center }}\\right)}{\\sum_{\\omega \\in \\text { vocab }} \\exp \\left(u_\\omega^T v_{\\text {center }}\\right)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7be53db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocabulary)\n",
    "\n",
    "def get_input_tensor(tensor):\n",
    "    '''Transform 1D tensor of word indexes to one-hot encoded 2D tensor'''\n",
    "    size = [*tensor.shape][0]\n",
    "    inp = torch.zeros(size, vocab_size).scatter_(1, tensor.unsqueeze(1), 1.)\n",
    "    return Variable(inp).float()\n",
    "\n",
    "# Using embedding size of 5\n",
    "\n",
    "embedding_dims = 5\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a7968",
   "metadata": {},
   "source": [
    "Next, weight initialization. Look above on the architecture of NN. W1 matrix of size `vocab_size  ×\n",
    "  embedding_dims`, W2 of shape `embedding_dims × vocab_size`. Pay attention we put requires_grad as True, because we want NN to compute gradients for those weights matices for their optimization. Function torch.randn randomly initialize weights. But very important to initialize weights correctly. What does it mean? Weights should be initialized to small random numbers. If you are not careful enough with this step, model can generate unexpected and not useful results. For this uniform function is used here, it limits bounds of weights to  (−0.5/\n",
    " embedding_dims,  0.5/\n",
    " embedding_dims)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c914501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape is: torch.Size([20, 5]), W2 shape is: torch.Size([5, 20])\n"
     ]
    }
   ],
   "source": [
    "initrange = 0.5 / embedding_dims\n",
    "W1 = Variable(torch.randn(vocab_size, embedding_dims, device=device).uniform_(-initrange, initrange).float(), requires_grad=True) # shape V*H\n",
    "W2 = Variable(torch.randn(embedding_dims, vocab_size, device=device).uniform_(-initrange, initrange).float(), requires_grad=True) #shape H*V\n",
    "print(f'W1 shape is: {W1.shape}, W2 shape is: {W2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd338fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 2e-1\n",
    "lr_decay = 0.99\n",
    "loss_hist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac0b6c",
   "metadata": {},
   "source": [
    "Here we use DataLoader from PyTorch, it loads data by batches. That iss very useful tool, if you are not familiar \n",
    "with it I encourage you to have a look to avoid unnecessary coding. Our dataset is very small, so we don't need \n",
    "DataLoader here, it's added just for learning, that's why batch_size equals the dataset's number of rows. \n",
    "we will use the whole dataset for one iteration, here one iteration == one epoch. Pay attention, that \n",
    "get_input_tensor function defined above is used only for input layer, that's because CrossEntropyLoss expect true \n",
    "outputs as vector in long format, provided by DataLoader.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a1b19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss = 2.998577833175659\n",
      "Epoch 50, loss = 2.625443696975708\n",
      "Epoch 100, loss = 1.2810331583023071\n",
      "Epoch 150, loss = 1.0042035579681396\n",
      "Epoch 200, loss = 0.9315589070320129\n",
      "Epoch 250, loss = 1.0800772905349731\n",
      "Epoch 300, loss = 1.3391231298446655\n",
      "Epoch 350, loss = 1.0540748834609985\n",
      "Epoch 400, loss = 1.5374940633773804\n",
      "Epoch 450, loss = 1.3225044012069702\n",
      "Epoch 500, loss = 1.1197007894515991\n",
      "Epoch 550, loss = 1.1503740549087524\n",
      "Epoch 600, loss = 1.3379549980163574\n",
      "Epoch 650, loss = 1.3130196332931519\n",
      "Epoch 700, loss = 1.4010224342346191\n",
      "Epoch 750, loss = 1.1631858348846436\n",
      "Epoch 800, loss = 1.1985926628112793\n",
      "Epoch 850, loss = 1.2639422416687012\n",
      "Epoch 900, loss = 1.1020801067352295\n",
      "Epoch 950, loss = 1.062979817390442\n",
      "Epoch 1000, loss = 1.0206540822982788\n",
      "Epoch 1050, loss = 1.003631830215454\n",
      "Epoch 1100, loss = 0.9823724627494812\n",
      "Epoch 1150, loss = 0.9604396820068359\n",
      "Epoch 1200, loss = 0.9419291615486145\n",
      "Epoch 1250, loss = 0.9268764853477478\n",
      "Epoch 1300, loss = 0.920346200466156\n",
      "Epoch 1350, loss = 0.9180168509483337\n",
      "Epoch 1400, loss = 0.9171001315116882\n",
      "Epoch 1450, loss = 0.9159104228019714\n",
      "Epoch 1500, loss = 0.9144554734230042\n",
      "Epoch 1550, loss = 0.9127939343452454\n",
      "Epoch 1600, loss = 0.9109735488891602\n",
      "Epoch 1650, loss = 0.9090316891670227\n",
      "Epoch 1700, loss = 0.907004177570343\n",
      "Epoch 1750, loss = 0.9049401879310608\n",
      "Epoch 1800, loss = 0.902975857257843\n",
      "Epoch 1850, loss = 0.9017171263694763\n",
      "Epoch 1900, loss = 0.9016086459159851\n",
      "Epoch 1950, loss = 0.9016334414482117\n",
      "CPU times: user 516 ms, sys: 240 ms, total: 757 ms\n",
      "Wall time: 607 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epo in range(num_epochs):\n",
    "    for x,y in zip(DataLoader(train_emb.Input.values, batch_size=train_emb.shape[0]), DataLoader(train_emb.Output.values, batch_size=train_emb.shape[0])):\n",
    "        \n",
    "        # one-hot encode input tensor\n",
    "        input_tensor = get_input_tensor(x) #shape N*V\n",
    "     \n",
    "        # simple NN architecture\n",
    "        h = input_tensor.mm(W1) # shape 1*H\n",
    "        y_pred = h.mm(W2) # shape 1*V\n",
    "        \n",
    "        # define loss func\n",
    "        loss_f = torch.nn.CrossEntropyLoss() # see details: https://pytorch.org/docs/stable/nn.html\n",
    "        \n",
    "        #compute loss\n",
    "        loss = loss_f(y_pred, y)\n",
    "        \n",
    "        # bakpropagation step\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights using gradient descent. For this step we just want to mutate\n",
    "        # the values of w1 and w2 in-place; we don't want to build up a computational\n",
    "        # graph for the update steps, so we use the torch.no_grad() context manager\n",
    "        # to prevent PyTorch from building a computational graph for the updates\n",
    "        with torch.no_grad():\n",
    "            # SGD optimization is implemented in PyTorch, but it's very easy to implement manually providing better understanding of process\n",
    "            W1 -= learning_rate*W1.grad.data\n",
    "            W2 -= learning_rate*W2.grad.data\n",
    "            # zero gradients for next step\n",
    "            W1.grad.data.zero_()\n",
    "            W1.grad.data.zero_()\n",
    "    if epo%10 == 0:\n",
    "        learning_rate *= lr_decay\n",
    "    loss_hist.append(loss)\n",
    "    if epo%50 == 0:\n",
    "        print(f'Epoch {epo}, loss = {loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c1396df",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = W1.detach().numpy()\n",
    "W2 = W2.T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f6ed342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "W1_dec = svd.fit_transform(W1)\n",
    "x = W1_dec[:,0]\n",
    "y = W1_dec[:,1]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plot = plt.scatter(x, y)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.set_ylim(-0.9, 0.9)\n",
    "ax.set_xlim(-0.9, 1.0)\n",
    "for i, txt in enumerate(W1_dec):\n",
    "    #print(list(vocabulary.keys())[i])\n",
    "    label = list(vocabulary.keys())[i]\n",
    "\n",
    "    if label == 'cherry':\n",
    "        _y = y[i]+ 0.03\n",
    "        #print('inside')\n",
    "    elif label == 'mango':\n",
    "        _y = y[i] - 0.04\n",
    "    else:\n",
    "        _y = y[i]\n",
    "    if label == 'apple':\n",
    "        _x = x[i] + 0.06\n",
    "    elif label == 'bacon':\n",
    "        _x = x[i] - 0.2\n",
    "    else:\n",
    "        _x = x[i]+ 0.03\n",
    "\n",
    "    ax.annotate(list(vocabulary.keys())[i], (_x, _y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be498de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
