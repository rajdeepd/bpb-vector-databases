{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cacf39bc",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rajdeepd/bpb-vector-databases/blob/main/chapter10/Question_Answering_with_Weaviate_and_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1537e6",
   "metadata": {
    "id": "cb1537e6"
   },
   "source": [
    "# Question Answering in Weaviate with OpenAI Q&A module\n",
    "\n",
    "This notebook is prepared for a scenario where:\n",
    "* Your data is not vectorized\n",
    "* You want to run Q&A ([learn more](https://weaviate.io/developers/weaviate/modules/reader-generator-modules/qna-openai)) on your data based on the [OpenAI completions](https://beta.openai.com/docs/api-reference/completions) endpoint.\n",
    "* You want to use Weaviate with the OpenAI module ([text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai)), to generate vector embeddings for you.\n",
    "\n",
    "This notebook takes you through a simple flow to set up a Weaviate instance, connect to it (with OpenAI API key), configure data schema, import data (which will automatically generate vector embeddings for your data), and run question answering.\n",
    "\n",
    "## What is Weaviate\n",
    "\n",
    "Weaviate is an open-source vector search engine that stores data objects together with their vectors. This allows for combining vector search with structured filtering.\n",
    "\n",
    "Weaviate uses KNN algorithms to create an vector-optimized index, which allows your queries to run extremely fast. Learn more [here](https://weaviate.io/blog/why-is-vector-search-so-fast).\n",
    "\n",
    "Weaviate let's you use your favorite ML-models, and scale seamlessly into billions of data objects.\n",
    "\n",
    "### Deployment options\n",
    "\n",
    "Whatever your scenario or production setup, Weaviate has an option for you. You can deploy Weaviate in the following setups:\n",
    "* Self-hosted – you can deploy Weaviate with docker locally, or any server you want.\n",
    "* SaaS – you can use [Weaviate Cloud Service (WCS)](https://console.weaviate.io/) to host your Weaviate instances.\n",
    "* Hybrid-Saas – you can deploy Weaviate in your own private Cloud Service\n",
    "\n",
    "### Programming languages\n",
    "\n",
    "Weaviate offers four [client libraries](https://weaviate.io/developers/weaviate/client-libraries), which allow you to communicate from your apps:\n",
    "* [Python](https://weaviate.io/developers/weaviate/client-libraries/python)\n",
    "* [JavaScript](https://weaviate.io/developers/weaviate/client-libraries/javascript)\n",
    "* [Java](https://weaviate.io/developers/weaviate/client-libraries/java)\n",
    "* [Go](https://weaviate.io/developers/weaviate/client-libraries/go)\n",
    "\n",
    "Additionally, Weavaite has a [REST layer](https://weaviate.io/developers/weaviate/api/rest/objects). Basically you can call Weaviate from any language that supports REST requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45956173",
   "metadata": {
    "id": "45956173"
   },
   "source": [
    "## Demo Flow\n",
    "The demo flow is:\n",
    "- **Prerequisites Setup**: Create a Weaviate instance and install required libraries\n",
    "- **Connect**: Connect to your Weaviate instance\n",
    "- **Schema Configuration**: Configure the schema of your data\n",
    "    - *Note*: Here we can define which OpenAI Embedding Model to use\n",
    "    - *Note*: Here we can configure which properties to index on\n",
    "- **Import data**: Load a demo dataset and import it into Weaviate\n",
    "    - *Note*: The import process will automatically index your data - based on the configuration in the schema\n",
    "    - *Note*: You don't need to explicitly vectorize your data, Weaviate will communicate with OpenAI to do it for you.\n",
    "- **Run Queries**: Query\n",
    "    - *Note*: You don't need to explicitly vectorize your queries, Weaviate will communicate with OpenAI to do it for you.\n",
    "    - *Note*: The `qna-openai` module automatically communicates with the OpenAI completions endpoint.\n",
    "\n",
    "Once you've run through this notebook you should have a basic understanding of how to setup and use vector databases for question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a145e",
   "metadata": {
    "id": "2a4a145e"
   },
   "source": [
    "## OpenAI Module in Weaviate\n",
    "All Weaviate instances come equiped with the [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai) and the [qna-openai](https://weaviate.io/developers/weaviate/modules/reader-generator-modules/qna-openai) modules.\n",
    "\n",
    "The first module is responsible for handling vectorization at import (or any CRUD operations) and when you run a search query. The second module communicates with the OpenAI completions endpoint.\n",
    "\n",
    "### No need to manually vectorize data\n",
    "This is great news for you. With [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai) you don't need to manually vectorize your data, as Weaviate will call OpenAI for you whenever necessary.\n",
    "\n",
    "All you need to do is:\n",
    "1. provide your OpenAI API Key – when you connected to the Weaviate Client\n",
    "2. define which OpenAI vectorizer to use in your Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a618c5",
   "metadata": {
    "id": "f1a618c5"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start this project, we need setup the following:\n",
    "\n",
    "* create a `Weaviate` instance\n",
    "* install libraries\n",
    "    * `weaviate-client`\n",
    "    * `datasets`\n",
    "    * `apache-beam`\n",
    "* get your [OpenAI API key](https://beta.openai.com/account/api-keys)\n",
    "\n",
    "===========================================================\n",
    "### Create a Weaviate instance\n",
    "\n",
    "To create a Weaviate instance we have 2 options:\n",
    "\n",
    "1. (Recommended path) [Weaviate Cloud Service](https://console.weaviate.io/) – to host your Weaviate instance in the cloud. The free sandbox should be more than enough for this cookbook.\n",
    "2. Install and run Weaviate locally with Docker.\n",
    "\n",
    "#### Option 1 – WCS Installation Steps\n",
    "\n",
    "Use [Weaviate Cloud Service](https://console.weaviate.io/) (WCS) to create a free Weaviate cluster.\n",
    "1. create a free account and/or login to [WCS](https://console.weaviate.io/)\n",
    "2. create a `Weaviate Cluster` with the following settings:\n",
    "    * Sandbox: `Sandbox Free`\n",
    "    * Weaviate Version: Use default (latest)\n",
    "    * OIDC Authentication: `Disabled`\n",
    "3. your instance should be ready in a minute or two\n",
    "4. make a note of the `Cluster Id`. The link will take you to the full path of your cluster (you will need it later to connect to it). It should be something like: `https://your-project-name.weaviate.network`\n",
    "\n",
    "#### Option 2 – local Weaviate instance with Docker\n",
    "\n",
    "Install and run Weaviate locally with Docker.\n",
    "1. Download the [./docker-compose.yml](./docker-compose.yml) file\n",
    "2. Then open your terminal, navigate to where your docker-compose.yml folder, and start docker with: `docker-compose up -d`\n",
    "3. Once this is ready, your instance should be available at [http://localhost:8080](http://localhost:8080)\n",
    "\n",
    "Note. To shut down your docker instance you can call: `docker-compose down`\n",
    "\n",
    "##### Learn more\n",
    "To learn more, about using Weaviate with Docker see the [installation documentation](https://weaviate.io/developers/weaviate/installation/docker-compose)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9babafe",
   "metadata": {
    "id": "b9babafe"
   },
   "source": [
    "===========================================================    \n",
    "## Install required libraries\n",
    "\n",
    "Before running this project make sure to have the following libraries:\n",
    "\n",
    "### Weaviate Python client\n",
    "\n",
    "The [Weaviate Python client](https://weaviate.io/developers/weaviate/client-libraries/python) allows you to communicate with your Weaviate instance from your Python project.\n",
    "\n",
    "### datasets & apache-beam\n",
    "\n",
    "To load sample data, you need the `datasets` library and its' dependency `apache-beam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b04113f",
   "metadata": {
    "id": "2b04113f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 3.11.0 not found\n",
      "Requirement already satisfied: datasets in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (2.21.0)\n",
      "Requirement already satisfied: apache-beam in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (2.63.0)\n",
      "Requirement already satisfied: filelock in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (0.3.1.1)\n",
      "Requirement already satisfied: pandas in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (0.70.9)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (0.22.1)\n",
      "Requirement already satisfied: packaging in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (3.10.7)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (1.10.0)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (1.65.5)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (4.23.0)\n",
      "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (3.4.2)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (0.7.1)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (4.11.2)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (5.28.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (2024.1)\n",
      "Requirement already satisfied: redis<6,>=5.0.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (5.2.1)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (2023.12.25)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (4.12.2)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (0.23.0)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from apache-beam) (0.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: docopt in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (0.6.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.1.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.20.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from pymongo<5.0.0,>=3.8.0->apache-beam) (2.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "env: OPENAI_API_KEY=''"
     ]
    }
   ],
   "source": [
    "# Install the Weaviate client for Python\n",
    "!pip install weaviate-client>=3.11.0\n",
    "\n",
    "# Install datasets and apache-beam to load the sample datasets\n",
    "!pip install datasets apache-beam\n",
    "\n",
    "# Set OPENAI_API_KEY\n",
    "%env OPENAI_API_KEY=''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe86f4",
   "metadata": {
    "id": "36fe86f4"
   },
   "source": [
    "===========================================================\n",
    "## Prepare your OpenAI API key\n",
    "\n",
    "The `OpenAI API key` is used for vectorization of your data at import, and for queries.\n",
    "\n",
    "If you don't have an OpenAI API key, you can get one from [https://beta.openai.com/account/api-keys](https://beta.openai.com/account/api-keys).\n",
    "\n",
    "Once you get your key, please add it to your environment variables as `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88be138c",
   "metadata": {
    "id": "88be138c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "# Test that your OpenAI API key is correctly set as an environment variable\n",
    "# Note. if you run this notebook locally, you will need to reload your terminal and the notebook for the env variables to be live.\n",
    "import os\n",
    "\n",
    "# Note. alternatively you can set a temporary env variable like this:\n",
    "# os.environ['OPENAI_API_KEY'] = 'your-key-goes-here'\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print (\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print (\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91df4d5b",
   "metadata": {
    "id": "91df4d5b"
   },
   "source": [
    "## Connect to your Weaviate instance\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. test env variable `OPENAI_API_KEY` – **make sure** you completed the step in [#Prepare-your-OpenAI-API-key](#Prepare-your-OpenAI-API-key)\n",
    "2. connect to your Weaviate your `OpenAI API Key`\n",
    "3. and test the client connection\n",
    "\n",
    "### The client\n",
    "\n",
    "After this step, the `client` object will be used to perform all Weaviate-related operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc662c1b",
   "metadata": {
    "id": "cc662c1b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'weaviate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mweaviate\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'weaviate'"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "# Connect to your Weaviate instance\n",
    "# Note that Google Colab doesn't connect to the localhost. So it would be best if you have a WCS instance or a Weaviate cluster with access to the Internet.\n",
    "client = weaviate.Client(\n",
    "    url=\"https://jlffb15urjub6mtih5vjza.c0.asia-southeast1.gcp.weaviate.cloud\",\n",
    "#   url=\"http://localhost:8080/\",\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check if your instance is live and ready\n",
    "# This should return `True`\n",
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dac3c",
   "metadata": {
    "id": "7d3dac3c"
   },
   "source": [
    "# Schema\n",
    "\n",
    "In this section, we will:\n",
    "1. configure the data schema for your data\n",
    "2. select OpenAI module\n",
    "\n",
    "> This is the second and final step, which requires OpenAI specific configuration.\n",
    "> After this step, the rest of instructions wlll only touch on Weaviate, as the OpenAI tasks will be handled automatically.\n",
    "\n",
    "\n",
    "## What is a schema\n",
    "\n",
    "In Weaviate you create __schemas__ to capture each of the entities you will be searching.\n",
    "\n",
    "A schema is how you tell Weaviate:\n",
    "* what embedding model should be used to vectorize the data\n",
    "* what your data is made of (property names and types)\n",
    "* which properties should be vectorized and indexed\n",
    "\n",
    "In this cookbook we will use a dataset for `Articles`, which contains:\n",
    "* `title`\n",
    "* `content`\n",
    "* `url`\n",
    "\n",
    "We want to vectorize `title` and `content`, but not the `url`.\n",
    "\n",
    "To vectorize and query the data, we will use `text-embedding-ada-002`. For Q&A we will use `text-davinci-002`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894b911",
   "metadata": {
    "id": "f894b911",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clear up the schema, so that we can recreate it\n",
    "client.schema.delete_all()\n",
    "client.schema.get()\n",
    "\n",
    "# Define the Schema object to use `text-embedding-ada-002` on `title` and `content`, but skip it for `url`\n",
    "article_schema = {\n",
    "    \"class\": \"Article\",\n",
    "    \"description\": \"A collection of articles\",\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "          \"model\": \"ada\",\n",
    "          \"modelVersion\": \"002\",\n",
    "          \"type\": \"text\"\n",
    "        },\n",
    "        \"qna-openai\": {\n",
    "          \"model\": \"text-davinci-002\",\n",
    "          \"maxTokens\": 16,\n",
    "          \"temperature\": 0.0,\n",
    "          \"topP\": 1,\n",
    "          \"frequencyPenalty\": 0.0,\n",
    "          \"presencePenalty\": 0.0\n",
    "        }\n",
    "    },\n",
    "    \"properties\": [{\n",
    "        \"name\": \"title\",\n",
    "        \"description\": \"Title of the article\",\n",
    "        \"dataType\": [\"string\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"content\",\n",
    "        \"description\": \"Contents of the article\",\n",
    "        \"dataType\": [\"text\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"url\",\n",
    "        \"description\": \"URL to the article\",\n",
    "        \"dataType\": [\"string\"],\n",
    "        \"moduleConfig\": { \"text2vec-openai\": { \"skip\": True } }\n",
    "    }]\n",
    "}\n",
    "\n",
    "# add the Article schema\n",
    "client.schema.create_class(article_schema)\n",
    "\n",
    "# get the schema to make sure it worked\n",
    "client.schema.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9d2e1",
   "metadata": {
    "id": "e5d9d2e1"
   },
   "source": [
    "## Import data\n",
    "\n",
    "In this section we will:\n",
    "1. load the Simple Wikipedia dataset\n",
    "2. configure Weaviate Batch import (to make the import more efficient)\n",
    "3. import the data into Weaviate\n",
    "\n",
    "> Note: <br/>\n",
    "> Like mentioned before. We don't need to manually vectorize the data.<br/>\n",
    "> The [text2vec-openai](https://weaviate.io/developers/weaviate/modules/retriever-vectorizer-modules/text2vec-openai) module will take care of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3efadd",
   "metadata": {
    "id": "fc3efadd"
   },
   "outputs": [],
   "source": [
    "### STEP 1 - load the dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "from typing import List, Iterator\n",
    "\n",
    "# We'll use the datasets library to pull the Simple Wikipedia dataset for embedding\n",
    "dataset = list(load_dataset(\"wikipedia\", \"20220301.simple\")[\"train\"])\n",
    "\n",
    "# For testing, limited to 2.5k articles for demo purposes\n",
    "dataset = dataset[:2_500]\n",
    "\n",
    "# Limited to 25k articles for larger demo purposes\n",
    "# dataset = dataset[:25_000]\n",
    "\n",
    "# for free OpenAI acounts, you can use 50 objects\n",
    "# dataset = dataset[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044da96",
   "metadata": {
    "id": "5044da96"
   },
   "outputs": [],
   "source": [
    "### Step 2 - configure Weaviate Batch, with\n",
    "# - starting batch size of 100\n",
    "# - dynamically increase/decrease based on performance\n",
    "# - add timeout retries if something goes wrong\n",
    "\n",
    "client.batch.configure(\n",
    "    batch_size=250,\n",
    "    dynamic=True,\n",
    "    timeout_retries=3,\n",
    "#   callback=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15db8380",
   "metadata": {
    "id": "15db8380"
   },
   "outputs": [],
   "source": [
    "### Step 3 - import data\n",
    "\n",
    "print(\"Importing Articles\")\n",
    "\n",
    "counter=0\n",
    "\n",
    "with client.batch as batch:\n",
    "    for article in dataset:\n",
    "        if (counter %10 == 0):\n",
    "            print(f\"Import {counter} / {len(dataset)} \")\n",
    "\n",
    "        properties = {\n",
    "            \"title\": article[\"title\"],\n",
    "            \"content\": article[\"text\"],\n",
    "            \"url\": article[\"url\"]\n",
    "        }\n",
    "\n",
    "        batch.add_data_object(properties, \"Article\")\n",
    "        counter = counter+1\n",
    "\n",
    "print(\"Importing Articles complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658693c",
   "metadata": {
    "id": "3658693c"
   },
   "outputs": [],
   "source": [
    "# Test that all data has loaded – get object count\n",
    "result = (\n",
    "    client.query.aggregate(\"Article\")\n",
    "    .with_fields(\"meta { count }\")\n",
    "    .do()\n",
    ")\n",
    "print(\"Object count: \", result[\"data\"][\"Aggregate\"][\"Article\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d791186",
   "metadata": {
    "id": "0d791186"
   },
   "outputs": [],
   "source": [
    "# Test one article has worked by checking one object\n",
    "test_article = (\n",
    "    client.query\n",
    "    .get(\"Article\", [\"title\", \"url\", \"content\"])\n",
    "    .with_limit(1)\n",
    "    .do()\n",
    ")[\"data\"][\"Get\"][\"Article\"][0]\n",
    "\n",
    "print(test_article['title'])\n",
    "print(test_article['url'])\n",
    "print(test_article['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46050ca9",
   "metadata": {
    "id": "46050ca9"
   },
   "source": [
    "### Question Answering on the Data\n",
    "\n",
    "As above, we'll fire some queries at our new Index and get back results based on the closeness to our existing vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044aa93",
   "metadata": {
    "id": "b044aa93"
   },
   "outputs": [],
   "source": [
    "def qna(query, collection_name):\n",
    "\n",
    "    properties = [\n",
    "        \"title\", \"content\", \"url\",\n",
    "        \"_additional { answer { hasAnswer property result startPosition endPosition } distance }\"\n",
    "    ]\n",
    "\n",
    "    ask = {\n",
    "        \"question\": query,\n",
    "        \"properties\": [\"content\"]\n",
    "    }\n",
    "\n",
    "    result = (\n",
    "        client.query\n",
    "        .get(collection_name, properties)\n",
    "        .with_ask(ask)\n",
    "        .with_limit(1)\n",
    "        .do()\n",
    "    )\n",
    "\n",
    "    # Check for errors\n",
    "    if (\"errors\" in result):\n",
    "        print (\"\\033[91mYou probably have run out of OpenAI API calls for the current minute – the limit is set at 60 per minute.\")\n",
    "        raise Exception(result[\"errors\"][0]['message'])\n",
    "\n",
    "    print (f\"Objects returned: {len(result)}\")\n",
    "\n",
    "    return result[\"data\"][\"Get\"][collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2025f6",
   "metadata": {
    "id": "7e2025f6"
   },
   "outputs": [],
   "source": [
    "query_result = qna(\"Did Alanis Morissette win a Grammy?\", \"Article\")\n",
    "\n",
    "for i, article in enumerate(query_result):\n",
    "    print(f\"{i+1}. { article['_additional']['answer']['result']} (Distance: {round(article['_additional']['distance'],3) })\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c4a696",
   "metadata": {
    "id": "93c4a696"
   },
   "outputs": [],
   "source": [
    "query_result = qna(\"What is the capital of China?\", \"Article\")\n",
    "\n",
    "for i, article in enumerate(query_result):\n",
    "    if article['_additional']['answer']['hasAnswer'] == False:\n",
    "      print('No answer found')\n",
    "    else:\n",
    "      print(f\"{i+1}. { article['_additional']['answer']['result']} (Distance: {round(article['_additional']['distance'],3) })\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007be48",
   "metadata": {
    "id": "2007be48"
   },
   "source": [
    "Thanks for following along, you're now equipped to set up your own vector databases and use embeddings to do all kinds of cool things - enjoy! For more complex use cases please continue to work through other cookbook examples in this repo."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "envjan2025",
   "language": "python",
   "name": "envjan2025"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
