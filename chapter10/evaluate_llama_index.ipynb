{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdeepd/bpb-vector-databases/blob/main/chapter10/evaluate_llama_index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5D8OtrFwl05l"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "U7Evow7CmDkj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')\n",
        "len(OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxlcJPaZb_m7",
        "outputId": "a05c6172-57c5-46a1-97b1-4d4e35c830f0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set OpenAI api key**"
      ],
      "metadata": {
        "id": "5Q7tBgeKm6mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "dIDjKGj8mGNj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **use Paul Graham Essay text or the JIG and Fixture data from the below link or any document for building RAG pipeline.**\n",
        "\n",
        "# **Download Data**"
      ],
      "metadata": {
        "id": "IzcgZggwnLI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!curl 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -o 'data/paul_graham/paul_graham_essay.txt'\n",
        "\n",
        "# jig book data link https://drive.google.com/file/d/1e6fezR9seps-X4IOTdxRgA86QGVoW6_d/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnqNXUfunVGn",
        "outputId": "d874afb9-99b5-4c33-fa08-3561b8a6e791"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100    14  100    14    0     0     83      0 --:--:-- --:--:-- --:--:--    83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data and Build Index.**"
      ],
      "metadata": {
        "id": "PF2pRwM0nZXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()\n",
        "#documents = SimpleDirectoryReader(\"/content\").load_data()\n",
        "\n",
        "\n",
        "# Define an LLM\n",
        "llm = OpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Build index with a chunk_size of 512\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "_d9-jp0pnbnZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yd8kT-8pne-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build a QueryEngine and start querying.**"
      ],
      "metadata": {
        "id": "Z2a8_KfZngo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine()\n",
        "\n",
        "# By default it retrieves two similar nodes/ chunks. You can modify that in\n",
        "# vector_index.as_query_engine(similarity_top_k=k).\n",
        "\n",
        "\n",
        "response_vector = query_engine.query(\"What is the  percentage of the tight part tolerance must be applied to the tool\")\n",
        "response_vector_1 = query_engine.query(\"What is duplicate locating jigs and fixtures design\")"
      ],
      "metadata": {
        "id": "oRLPNGqUnj_M"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlQViVddnlGJ",
        "outputId": "32344614-a7d4-4b4b-a37e-b7611a5a3f32"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response='The percentage of the tight part tolerance that must be applied to the tool is typically around 10% to ensure proper fit and functionality.', source_nodes=[NodeWithScore(node=TextNode(id_='ea181f65-20df-465e-804f-1e3e0c83aa63', embedding=None, metadata={'file_path': '/content/data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 14, 'creation_date': '2025-02-01', 'last_modified_date': '2025-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b32c8d96-0fb2-4f67-adc7-7c7fb5adb6c7', node_type='4', metadata={'file_path': '/content/data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 14, 'creation_date': '2025-02-01', 'last_modified_date': '2025-02-01'}, hash='1f9537429e34f3954e7092b7d189474b69ed920fee02f16864871b3a49de5f37')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='404: Not Found', mimetype='text/plain', start_char_idx=0, end_char_idx=14, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.04420428305605965)], metadata={'ea181f65-20df-465e-804f-1e3e0c83aa63': {'file_path': '/content/data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 14, 'creation_date': '2025-02-01', 'last_modified_date': '2025-02-01'}})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**print and check the response**"
      ],
      "metadata": {
        "id": "i-nyz0-dnrfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_vector.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0NWSvvE6nvkM",
        "outputId": "1eb77503-4661-45e9-c0b4-582156ac2bb3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The percentage of the tight part tolerance that must be applied to the tool is typically around 10% to ensure proper fit and functionality.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_vector_1.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "ck3dmb3Dy38R",
        "outputId": "799a5726-653f-4d08-f8c5-c3db7d1570f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Duplicate locating jigs and fixtures design refers to the process of creating tools and equipment that aid in accurately positioning and holding workpieces during manufacturing or assembly. These jigs and fixtures are designed to ensure consistency and precision in the production of multiple identical parts by providing a reliable means of locating and securing the workpiece in the correct position.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_vector_1.response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUkUuXml5b8T",
        "outputId": "042ac4a6-88ad-47cc-d202-ccc5bf4492ee"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate locating jigs and fixtures design refers to the process of creating tools and equipment that aid in accurately positioning and holding workpieces during manufacturing or assembly. These jigs and fixtures are designed to ensure consistency and precision in the production of multiple identical parts by providing a reliable means of locating and securing the workpiece in the correct position.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the text in each of these retrieved nodes.\n",
        "# First retrieved node\n",
        "#response_vector.source_nodes[0].get_text()\n",
        "response_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uFAZBs3oMCC",
        "outputId": "4b3bff0d-c5f5-40a1-f80d-cc0e95f1935d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response='The percentage of the tight part tolerance that must be applied to the tool is typically around 10% to ensure proper fit and functionality.', source_nodes=[NodeWithScore(node=TextNode(id_='ea181f65-20df-465e-804f-1e3e0c83aa63', embedding=None, metadata={'file_path': '/content/data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 14, 'creation_date': '2025-02-01', 'last_modified_date': '2025-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b32c8d96-0fb2-4f67-adc7-7c7fb5adb6c7', node_type='4', metadata={'file_path': '/content/data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 14, 'creation_date': '2025-02-01', 'last_modified_date': '2025-02-01'}, hash='1f9537429e34f3954e7092b7d189474b69ed920fee02f16864871b3a49de5f37')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='404: Not Found', mimetype='text/plain', start_char_idx=0, end_char_idx=14, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.04420428305605965)], metadata={'ea181f65-20df-465e-804f-1e3e0c83aa63': {'file_path': '/content/data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 14, 'creation_date': '2025-02-01', 'last_modified_date': '2025-02-01'}})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second retrieved node\n",
        "len(response_vector.source_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzG68cHKoQR4",
        "outputId": "a39d6143-9e04-44f8-c48f-c4e989450594"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gy0wSN2Iptti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-Context Pair Generation:**"
      ],
      "metadata": {
        "id": "SDzjvo89pwZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset = generate_question_context_pairs(\n",
        "    nodes,\n",
        "    llm=llm,\n",
        "    num_questions_per_chunk=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQg5IemqpuCi",
        "outputId": "e8efc4b9-bcc3-4cba-f614-084a50379a5c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrieval Evaluation:**"
      ],
      "metadata": {
        "id": "DAJ6e1lkp2DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_index.as_retriever(similarity_top_k=2)"
      ],
      "metadata": {
        "id": "RagG50SSp4LA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mean Reciprocal Rank (MRR):**"
      ],
      "metadata": {
        "id": "hSHbUMLZp9ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "CzS6LjO9p8ob"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
      ],
      "metadata": {
        "id": "BOOGKWduqCsb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(name, eval_results):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame(\n",
        "        {\"Retriever Name\": [name], \"Hit Rate\": [hit_rate], \"MRR\": [mrr]}\n",
        "    )\n",
        "\n",
        "    return metric_df"
      ],
      "metadata": {
        "id": "Y9TTNfOGqGlK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_results(\"OpenAI Embedding Retriever\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ymOL8TD_qLBc",
        "outputId": "41ac3090-8bc6-4545-dedd-50f4237471f5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Retriever Name  Hit Rate  MRR\n",
              "0  OpenAI Embedding Retriever       1.0  1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c51438e-7be0-45a5-8a75-ac021ee8152a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Retriever Name</th>\n",
              "      <th>Hit Rate</th>\n",
              "      <th>MRR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OpenAI Embedding Retriever</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c51438e-7be0-45a5-8a75-ac021ee8152a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c51438e-7be0-45a5-8a75-ac021ee8152a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c51438e-7be0-45a5-8a75-ac021ee8152a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display_results(\\\"OpenAI Embedding Retriever\\\", eval_results)\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Retriever Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"OpenAI Embedding Retriever\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hit Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MRR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Response Evaluation**"
      ],
      "metadata": {
        "id": "u3ttytVVw_WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of queries from the above created dataset\n",
        "\n",
        "queries = list(qa_dataset.queries.values())"
      ],
      "metadata": {
        "id": "YTY0CUNQxEzc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhZ50rkGxILf",
        "outputId": "b503e5a3-f050-4042-833b-47b7bdf56868"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"What does the error code '404' typically represent in computer networking?\",\n",
              " \"Can you explain some potential reasons why a 'Not Found' error might occur?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Faithfulness Evaluator**"
      ],
      "metadata": {
        "id": "upjvFWiPxLVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt-3.5-turbo\n",
        "#gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "from llama_index.core import Settings\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
        "#Settings.node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=20)\n",
        "#Settings.num_output = 512\n",
        "#Settings.context_window = 3900\n",
        "##service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n",
        "\n",
        "# gpt-3.5-turbo-16k-0613\n",
        "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "#service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n",
        "\n",
        "#gpt-4\n",
        "#gpt35T = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "#service_context_gpt4 = ServiceContext.from_defaults(llm=gpt35T)"
      ],
      "metadata": {
        "id": "D6aa4UhsxKc1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a QueryEngine with gpt-3.5-turbo service_context to generate response for the query.\n",
        "#vector_index = VectorStoreIndex(nodes, service_context = service_context_gpt35)\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "#query_engine = VectorStoreIndex.as_query_engine()"
      ],
      "metadata": {
        "id": "NbUYFuE2xxyc"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a FaithfulnessEvaluator\n",
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "#faithfulness_gpt4 = FaithfulnessEvaluator(service_context=service_context_gpt4)\n",
        "faithfulness_gpt4  = FaithfulnessEvaluator(llm=gpt4)\n"
      ],
      "metadata": {
        "id": "Yo0ziJl0x2go"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_query = queries[1]\n",
        "\n",
        "eval_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "x4zuyDS6x8_3",
        "outputId": "2348143d-901c-45f4-b254-7830dc4e069a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Can you explain some potential reasons why a 'Not Found' error might occur?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate response first and use faithfull evaluator.\n",
        "response_vector = query_engine.query(eval_query)"
      ],
      "metadata": {
        "id": "ept1j-uIx-M-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute faithfulness evaluation\n",
        "\n",
        "eval_result = faithfulness_gpt4.evaluate_response(response=response_vector)"
      ],
      "metadata": {
        "id": "qCb11ccuyDsk"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can check passing parameter in eval_result if it passed the evaluation.\n",
        "eval_result.passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIHWBLiryDmb",
        "outputId": "b5a556de-b7c3-4e0c-dd48-a2a853a92d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Relevancy Evaluator**"
      ],
      "metadata": {
        "id": "ioIvPMM7yHOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import RelevancyEvaluator\n",
        "\n",
        "#relevancy_gpt4 = RelevancyEvaluator(service_context=service_context_gpt4)\n",
        "relevancy_gpt4 = RelevancyEvaluator(llm=gpt4)"
      ],
      "metadata": {
        "id": "vhZyZd-AyLUz"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a query\n",
        "query = queries[1]\n",
        "\n",
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gIX3WHxvySkC",
        "outputId": "df876da1-c2ec-488f-85d2-4b4a803b5026"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Can you explain some potential reasons why a 'Not Found' error might occur?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate response.\n",
        "# response_vector has response and source nodes (retrieved context)\n",
        "response_vector = query_engine.query(query)\n",
        "\n",
        "# Relevancy evaluation\n",
        "eval_result = relevancy_gpt4.evaluate_response(\n",
        "    query=query, response=response_vector\n",
        ")"
      ],
      "metadata": {
        "id": "Tk1WJ88fyVJV"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can check passing parameter in eval_result if it passed the evaluation.\n",
        "eval_result.passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn0GhJKgyW_N",
        "outputId": "d1eaef4c-9445-4bb3-94ea-443316af86d1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can get the feedback for the evaluation.\n",
        "eval_result.feedback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eqySQ7iVyZSw",
        "outputId": "e8b592fd-8e42-4304-985a-0a2e9ebb54a6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YES'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Evaluator**"
      ],
      "metadata": {
        "id": "9HqXLL8_ydBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import BatchEvalRunner\n",
        "\n",
        "# Let's pick top 10 queries to do evaluation\n",
        "batch_eval_queries = queries[:10]\n",
        "\n",
        "# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n",
        "runner = BatchEvalRunner(\n",
        "    {\"faithfulness\": faithfulness_gpt4, \"relevancy\": relevancy_gpt4},\n",
        "    workers=8,\n",
        ")\n",
        "\n",
        "# Compute evaluation\n",
        "eval_results = await runner.aevaluate_queries(\n",
        "    query_engine, queries=batch_eval_queries\n",
        ")"
      ],
      "metadata": {
        "id": "CouVNEgDycsM"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get faithfulness score\n",
        "\n",
        "faithfulness_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['faithfulness'])\n",
        "\n",
        "faithfulness_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZR0KgheykrX",
        "outputId": "f74e6713-b964-47ac-d940-b0fd1564f791"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get relevancy score\n",
        "\n",
        "relevancy_score = sum(result.passing for result in eval_results['relevancy']) / len(eval_results['relevancy'])\n",
        "\n",
        "relevancy_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsBtSM-Vym1B",
        "outputId": "4cc376aa-4190-45d9-9fe1-90fb0e49f294"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXv78Sfw0g0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}