{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e10297-4bc4-4f90-9498-a98fa574addf",
   "metadata": {},
   "source": [
    "# Optimization by Prompting\" for RAG\n",
    "Inspired by the Optimization by Prompting paper by Yang et al., in this guide we test the ability of a \"meta-prompt\" to optimize our prompt for better RAG performance. The process is roughly as follows:\n",
    "\n",
    "The prompt to be optimized is our standard QA prompt template for RAG, specifically the instruction prefix.\n",
    "We have a \"meta-prompt\" that takes in previous prefixes/scores + an example of the task, and spits out another prefix.\n",
    "For every candidate prefix, we compute a \"score\" through correctness evaluation - comparing a dataset of predicted answers (using the QA prompt) to a candidate dataset. If you don't have it already, you can generate with GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2aa18d52-2c59-46d2-ac9c-1cb62be54e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q llama-index-llms-openai\n",
    "#%pip install  -q llama-index-readers-file pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7031976c-92df-463f-8cdf-72247601eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b307f6b2-2c65-411d-a5ee-f805f58c63fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir data && wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a61313-16a3-4331-80ec-7d04b7bece0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8853e6ff-3db4-4307-a243-dc4bf4a5e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.readers.file import UnstructuredReader\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85e29f3-168c-4949-a103-6f3bfd4e8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFReader()\n",
    "docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4edd396-6dd5-4c4e-9384-297ff6b04e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2 : Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗Louis Martin†Kevin Stone†\\nPeter Al'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs0[0].text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1da3255-90ec-418b-b204-c442e95bac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d745514b-64f9-4792-8302-8de4224f0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import IndexNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f466f8-023b-4348-805c-e8ba79196cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e094992-faea-43a3-92e6-fe6dab24197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6072cc2-421f-4fb7-9398-e1ccaa1fcd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30243397-732d-4407-bbc1-4620026999cc",
   "metadata": {},
   "source": [
    "## Setup Vector Index over this Data\n",
    "We load this data into an in-memory vector store (embedded with OpenAI embeddings).\n",
    "We'll be aggressively optimizing the QA prompt for this RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ab0afb1-d2ad-47cc-bc1c-ed1b81ec1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"API_KEY\"][:10]\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.environ[\"API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4195787f-79cb-41ea-9c06-4a204b177f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac5a023-66a2-4f9b-a4f2-db3033da71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = VectorStoreIndex(base_nodes)\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53f8e0-9eda-4a8e-8561-8577765a210e",
   "metadata": {},
   "source": [
    "\n",
    "## \"Golden\" Dataset\n",
    "\n",
    "Here we generate a dataset of ground-truth QA pairs (or load it).\n",
    "\n",
    "This will be used for two purposes:\n",
    "\n",
    "* To generate some exemplars that we can put into the meta-prompt to illustrate the task\n",
    "* To generate an evaluation dataset to compute our objective score - so that the meta-prompt can try optimizing for this score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a64ab5e-3b76-4ed2-a60f-4a93774a5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import DatasetGenerator, QueryResponseDataset\n",
    "from llama_index.core.node_parser import SimpleNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d0da50-8dd1-458e-b8f2-3aef7e518213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/md/s61y7jv50ll25yy2d92p9qrc0000gp/T/ipykernel_27784/1627729211.py:1: DeprecationWarning: Call to deprecated class DatasetGenerator. (Deprecated in favor of `RagDatasetGenerator` which should be used instead.)\n",
      "  dataset_generator = DatasetGenerator(\n"
     ]
    }
   ],
   "source": [
    "dataset_generator = DatasetGenerator(\n",
    "    base_nodes[:10],\n",
    "    llm=OpenAI(model=\"gpt-4o\"),\n",
    "    show_progress=True,\n",
    "    num_questions_per_chunk=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c068f32a-fe32-4628-94cf-153499272a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  4.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  2.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  2.64it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.43it/s]\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3/5 [00:02<00:01,  1.25it/s]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.036936384016344914 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29863, Requested 881. Please try again in 1.488s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.61s/it]\n",
      " 40%|████████████████████████████████████████████████████████▍                                                                                    | 2/5 [00:03<00:05,  1.84s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.9954762332052325 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29842, Requested 1037. Please try again in 1.758s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.10s/it]\n",
      " 40%|████████████████████████████████████████████████████████▍                                                                                    | 2/5 [00:03<00:05,  1.78s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.728918922310981 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29509, Requested 709. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.4942676409259833 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29502, Requested 716. Please try again in 436ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5276006892073145 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29495, Requested 714. Please try again in 418ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      " 80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                            | 4/5 [00:07<00:02,  2.09s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.20146944609185202 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29579, Requested 709. Please try again in 576ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:10<00:00,  2.05s/it]\n",
      " 40%|████████████████████████████████████████████████████████▍                                                                                    | 2/5 [00:05<00:06,  2.32s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.17370321715257386 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29450, Requested 922. Please try again in 744ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.22961714800129496 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29441, Requested 927. Please try again in 736ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.07428698124171762 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29441, Requested 932. Please try again in 746ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████▌                                                        | 3/5 [00:09<00:06,  3.21s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.8315893851645879 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29122, Requested 922. Please try again in 88ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:12<00:00,  2.53s/it]\n",
      " 40%|████████████████████████████████████████████████████████▍                                                                                    | 2/5 [00:05<00:08,  2.95s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.0891138736523065 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29834, Requested 1196. Please try again in 2.06s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.40340215007397995 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29831, Requested 1197. Please try again in 2.056s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.63s/it]\n",
      "/Users/rdua/work/github/rajdeepd/bpb-vector-databases/my-python3-env/lib/python3.10/site-packages/llama_index/core/evaluation/dataset_generation.py:296: DeprecationWarning: Call to deprecated class QueryResponseDataset. (Deprecated in favor of `LabelledRagDataset` which should be used instead.)\n",
      "  return QueryResponseDataset(queries=queries, responses=responses_dict)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_dataset = await dataset_generator.agenerate_dataset_from_nodes(num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a375e0f-f01d-4fdf-b617-da1324793cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"data/llama2_eval_qr_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e598946-d3a9-46b4-88c6-862d0202da31",
   "metadata": {},
   "source": [
    "## Dataset Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "058c4298-14bb-46c7-8132-ea76e720f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "full_qr_pairs = eval_dataset.qr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790ea50e-8363-4bde-8a8d-45675647e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_exemplars = 2\n",
    "num_eval = 20\n",
    "exemplar_qr_pairs = random.sample(full_qr_pairs, num_exemplars)\n",
    "\n",
    "eval_qr_pairs = random.sample(full_qr_pairs, num_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce49aed-894f-4757-8202-fd0911a545f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exemplar_qr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57791ffd-a78d-4c67-8753-e1051da52a0b",
   "metadata": {},
   "source": [
    "## Prompt Optimization\n",
    "\n",
    "We now define the functions needed for prompt optimization. We first define an evaluator, and then we setup the meta-prompt which produces candidate instruction prefixes.\n",
    "\n",
    "Finally we define and run the prompt optimization loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b719d29-89d6-4c33-b046-c7297c2ffcca",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74c6e03-6e0d-4bc5-a28a-4d50712112b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.eval_utils import get_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea6dc8ee-f0ea-470e-b0cb-b0712aae16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import CorrectnessEvaluator, BatchEvalRunner\n",
    "\n",
    "evaluator_c = CorrectnessEvaluator(llm=OpenAI(model=\"gpt-4o\"))\n",
    "evaluator_dict = {\n",
    "    \"correctness\": evaluator_c,\n",
    "}\n",
    "batch_runner = BatchEvalRunner(evaluator_dict, workers=2, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb179b87-f280-4971-bcb0-0470d1ed0856",
   "metadata": {},
   "source": [
    "### Correctness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ca61829-e2da-4013-b6de-f518a69a24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_correctness(query_engine, eval_qa_pairs, batch_runner):\n",
    "    # then evaluate\n",
    "    # TODO: evaluate a sample of generated results\n",
    "    eval_qs = [q for q, _ in eval_qa_pairs]\n",
    "    eval_answers = [a for _, a in eval_qa_pairs]\n",
    "    pred_responses = get_responses(eval_qs, query_engine, show_progress=True)\n",
    "\n",
    "    eval_results = await batch_runner.aevaluate_responses(\n",
    "        eval_qs, responses=pred_responses, reference=eval_answers\n",
    "    )\n",
    "    avg_correctness = np.array(\n",
    "        [r.score for r in eval_results[\"correctness\"]]\n",
    "    ).mean()\n",
    "    return avg_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3452af31-f521-41fa-bcb7-72aa09494c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_PROMPT_KEY = \"response_synthesizer:text_qa_template\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd25c0f5-6dd0-4192-8eee-6e7fa675474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63eda500-f240-4a1a-a4b6-b0ec4ef6197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tmpl_str = (\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_tmpl = PromptTemplate(qa_tmpl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b36e86b-022c-4ecc-a5dd-e3d16fb9a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(query_engine.get_prompts()[QA_PROMPT_KEY].get_template())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11494019-8aed-4aa6-808e-cc63703be876",
   "metadata": {},
   "source": [
    "### Define Metaprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b16df8f7-d6de-45e3-8be7-b2018facd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_tmpl_str = \"\"\"\\\n",
    "Your task is to generate the instruction <INS>. Below are some previous instructions with their scores.\n",
    "The score ranges from 1 to 5.\n",
    "\n",
    "{prev_instruction_score_pairs}\n",
    "\n",
    "Below we show the task. The <INS> tag is prepended to the below prompt template, e.g. as follows:\n",
    "\n",
    "```\n",
    "<INS>\n",
    "{prompt_tmpl_str}\n",
    "```\n",
    "\n",
    "The prompt template contains template variables. Given an input set of template variables, the formatted prompt is then given to an LLM to get an output.\n",
    "\n",
    "Some examples of template variable inputs and expected outputs are given below to illustrate the task. **NOTE**: These do NOT represent the \\\n",
    "entire evaluation dataset.\n",
    "\n",
    "{qa_pairs_str}\n",
    "\n",
    "We run every input in an evaluation dataset through an LLM. If the LLM-generated output doesn't match the expected output, we mark it as wrong (score 0).\n",
    "A correct answer has a score of 1. The final \"score\" for an instruction is the average of scores across an evaluation dataset.\n",
    "Write your new instruction (<INS>) that is different from the old ones and has a score as high as possible.\n",
    "\n",
    "Instruction (<INS>): \\\n",
    "\"\"\"\n",
    "\n",
    "meta_tmpl = PromptTemplate(meta_tmpl_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7645aa8-c7d4-4e9e-ba84-5c600bc482b2",
   "metadata": {},
   "source": [
    "### Prompt Optimization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d251845c-cdf8-4162-aec0-0955ac29954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def format_meta_tmpl(\n",
    "    prev_instr_score_pairs,\n",
    "    prompt_tmpl_str,\n",
    "    qa_pairs,\n",
    "    meta_tmpl,\n",
    "):\n",
    "    \"\"\"Call meta-prompt to generate new instruction.\"\"\"\n",
    "    # format prev instruction score pairs.\n",
    "    pair_str_list = [\n",
    "        f\"Instruction (<INS>):\\n{instr}\\nScore:\\n{score}\"\n",
    "        for instr, score in prev_instr_score_pairs\n",
    "    ]\n",
    "    full_instr_pair_str = \"\\n\\n\".join(pair_str_list)\n",
    "\n",
    "    # now show QA pairs with ground-truth answers\n",
    "    qa_str_list = [\n",
    "        f\"query_str:\\n{query_str}\\nAnswer:\\n{answer}\"\n",
    "        for query_str, answer in qa_pairs\n",
    "    ]\n",
    "    full_qa_pair_str = \"\\n\\n\".join(qa_str_list)\n",
    "\n",
    "    fmt_meta_tmpl = meta_tmpl.format(\n",
    "        prev_instruction_score_pairs=full_instr_pair_str,\n",
    "        prompt_tmpl_str=prompt_tmpl_str,\n",
    "        qa_pairs_str=full_qa_pair_str,\n",
    "    )\n",
    "    return fmt_meta_tmpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ffd54f2-1395-4173-841e-c1fcac91197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_prompt_template(cur_instr: str, prompt_tmpl):\n",
    "    tmpl_str = prompt_tmpl.get_template()\n",
    "    new_tmpl_str = cur_instr + \"\\n\" + tmpl_str\n",
    "    new_tmpl = PromptTemplate(new_tmpl_str)\n",
    "    return new_tmpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16b8c5e4-c646-4885-b6ab-5ee45158ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def _parse_meta_response(meta_response: str):\n",
    "    return str(meta_response).split(\"\\n\")[0]\n",
    "\n",
    "\n",
    "async def optimize_prompts(\n",
    "    query_engine,\n",
    "    initial_instr: str,\n",
    "    base_prompt_tmpl,\n",
    "    meta_tmpl,\n",
    "    meta_llm,\n",
    "    batch_eval_runner,\n",
    "    eval_qa_pairs,\n",
    "    exemplar_qa_pairs,\n",
    "    num_iterations: int = 5,\n",
    "):\n",
    "    prev_instr_score_pairs = []\n",
    "    base_prompt_tmpl_str = base_prompt_tmpl.get_template()\n",
    "\n",
    "    cur_instr = initial_instr\n",
    "    for idx in range(num_iterations):\n",
    "        # TODO: change from -1 to 0\n",
    "        if idx > 0:\n",
    "            # first generate\n",
    "            fmt_meta_tmpl = format_meta_tmpl(\n",
    "                prev_instr_score_pairs,\n",
    "                base_prompt_tmpl_str,\n",
    "                exemplar_qa_pairs,\n",
    "                meta_tmpl,\n",
    "            )\n",
    "            meta_response = meta_llm.complete(fmt_meta_tmpl)\n",
    "            print(fmt_meta_tmpl)\n",
    "            print(str(meta_response))\n",
    "            # Parse meta response\n",
    "            cur_instr = _parse_meta_response(meta_response)\n",
    "\n",
    "        # append instruction to template\n",
    "        new_prompt_tmpl = get_full_prompt_template(cur_instr, base_prompt_tmpl)\n",
    "        query_engine.update_prompts({QA_PROMPT_KEY: new_prompt_tmpl})\n",
    "\n",
    "        avg_correctness = await get_correctness(\n",
    "            query_engine, eval_qa_pairs, batch_runner\n",
    "        )\n",
    "        prev_instr_score_pairs.append((cur_instr, avg_correctness))\n",
    "\n",
    "    # find the instruction with the highest score\n",
    "    max_instr_score_pair = max(\n",
    "        prev_instr_score_pairs, key=lambda item: item[1]\n",
    "    )\n",
    "\n",
    "    # return the instruction\n",
    "    return max_instr_score_pair[0], prev_instr_score_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9d183db-d27e-4dee-acff-cb5bbcd2cffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and pre-seed query engine with the prompt\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)\n",
    "# query_engine.update_prompts({QA_PROMPT_KEY: qa_tmpl})\n",
    "\n",
    "# get the base qa prompt (without any instruction prefix)\n",
    "base_qa_prompt = query_engine.get_prompts()[QA_PROMPT_KEY]\n",
    "\n",
    "\n",
    "initial_instr = \"\"\"\\\n",
    "You are a QA assistant.\n",
    "Context information is below. Given the context information and not prior knowledge, \\\n",
    "answer the query. \\\n",
    "\"\"\"\n",
    "\n",
    "# this is the \"initial\" prompt template\n",
    "# implicitly used in the first stage of the loop during prompt optimization\n",
    "# here we explicitly capture it so we can use it for evaluation\n",
    "old_qa_prompt = get_full_prompt_template(initial_instr, base_qa_prompt)\n",
    "\n",
    "meta_llm = OpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b287da7-90cc-4f36-906d-02178683557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 16/20 [00:06<00:02,  1.64it/s]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.059292011608630624 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 28698, Requested 1757. Please try again in 910ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.2612950335056601 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 28628, Requested 1875. Please try again in 1.006s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6174787597666808 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 28602, Requested 1894. Please try again in 992ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.35221323885322553 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29938, Requested 2135. Please try again in 4.146s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                    | 17/20 [00:08<00:03,  1.11s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 1.851237014818903 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29749, Requested 1875. Please try again in 3.248s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:20<00:00,  1.04s/it]\n",
      " 40%|████████████████████████████████████████████████████████                                                                                    | 8/20 [00:08<00:13,  1.12s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.15958440729964452 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29244, Requested 1028. Please try again in 544ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      " 75%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                  | 15/20 [00:16<00:06,  1.28s/it]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.5173243684850892 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29075, Requested 1332. Please try again in 814ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:22<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>} template_vars=['context_str', 'query_str'] kwargs={} output_parser=None template_var_mappings=None function_mappings=None template='You are a QA assistant.\\nContext information is below. Given the context information and not prior knowledge, answer the query. \\nContext information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_instr, prev_instr_score_pairs = await optimize_prompts(\n",
    "    query_engine,\n",
    "    initial_instr,\n",
    "    base_qa_prompt,\n",
    "    meta_tmpl,\n",
    "    meta_llm,  # note: treat llm as meta_llm\n",
    "    batch_runner,\n",
    "    eval_qr_pairs,\n",
    "    exemplar_qr_pairs,\n",
    "    num_iterations=1,\n",
    ")\n",
    "\n",
    "\n",
    "new_qa_prompt = query_engine.get_prompts()[QA_PROMPT_KEY]\n",
    "print(new_qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdb830f9-af79-4677-9087-5b1f8b8a6d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(metadata={'prompt_type': <PromptType.CUSTOM: 'custom'>}, template_vars=['context_str', 'query_str'], kwargs={}, output_parser=None, template_var_mappings=None, function_mappings=None, template='You are a QA assistant.\\nContext information is below. Given the context information and not prior knowledge, answer the query. \\nContext information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query_str}\\nAnswer: ')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "633346f5-bccd-45c1-9d9d-2c500f7144ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('You are a QA assistant.\\nContext information is below. Given the context information and not prior knowledge, answer the query. ',\n",
       "  3.975)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_instr_score_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "529cb973-9500-42bd-abbd-3b3dcb607156",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_eval_qs = [q for q, _ in full_qr_pairs]\n",
    "full_eval_answers = [a for _, a in full_qr_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddaf143e-b213-4fc3-9f8f-841ca996bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 16/20 [00:06<00:02,  1.94it/s]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.3933728782400451 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29555, Requested 2135. Please try again in 3.38s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.784100908752599 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 29532, Requested 2131. Please try again in 3.326s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:27<00:00,  1.39s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:11<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "## Evaluate with base QA prompt\n",
    "\n",
    "query_engine.update_prompts({QA_PROMPT_KEY: old_qa_prompt})\n",
    "avg_correctness_old = await get_correctness(\n",
    "    query_engine, full_qr_pairs, batch_runner\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67cd2931-f03e-465c-b534-1ab9a7329b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.825\n"
     ]
    }
   ],
   "source": [
    "print(avg_correctness_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a6314f53-91d1-4950-a572-88af2a8f2569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 18/20 [00:08<00:01,  1.01it/s]Retrying llama_index.llms.openai.base.OpenAI._achat in 0.20162978968196033 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 28135, Requested 1894. Please try again in 58ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "Retrying llama_index.llms.openai.base.OpenAI._achat in 0.6678360179459327 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-wDdFfjYtAtzZ6OpmLVkRR7UA on tokens per min (TPM): Limit 30000, Used 27933, Requested 2116. Please try again in 98ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:16<00:00,  1.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:22<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "## Evaluate with \"optimized\" prompt\n",
    "\n",
    "query_engine.update_prompts({QA_PROMPT_KEY: new_qa_prompt})\n",
    "avg_correctness_new = await get_correctness(\n",
    "    query_engine, full_qr_pairs, batch_runner\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75ceb184-b0af-44f2-aa0d-f4fb7d6c4982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(avg_correctness_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9728e-0685-4557-8e3d-326af12629b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-python3-kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
